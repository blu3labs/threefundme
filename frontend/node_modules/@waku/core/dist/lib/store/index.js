import { sha256 } from "@noble/hashes/sha256";
import { proto_store as proto } from "@waku/proto";
import { ensurePubsubTopicIsConfigured, isDefined } from "@waku/utils";
import { Logger } from "@waku/utils";
import { concat, utf8ToBytes } from "@waku/utils/bytes";
import all from "it-all";
import * as lp from "it-length-prefixed";
import { pipe } from "it-pipe";
import { Uint8ArrayList } from "uint8arraylist";
import { BaseProtocol } from "../base_protocol.js";
import { DefaultPubSubTopic } from "../constants.js";
import { toProtoMessage } from "../to_proto_message.js";
import { HistoryRpc, PageDirection } from "./history_rpc.js";
var HistoryError = proto.HistoryResponse.HistoryError;
const log = new Logger("store");
export const StoreCodec = "/vac/waku/store/2.0.0-beta4";
export const DefaultPageSize = 10;
export { PageDirection };
/**
 * Implements the [Waku v2 Store protocol](https://rfc.vac.dev/spec/13/).
 *
 * The Waku Store protocol can be used to retrieved historical messages.
 */
class Store extends BaseProtocol {
    pubsubTopics;
    NUM_PEERS_PROTOCOL = 1;
    constructor(libp2p, options) {
        super(StoreCodec, libp2p.components);
        this.pubsubTopics = options?.pubsubTopics ?? [DefaultPubSubTopic];
    }
    /**
     * Processes messages based on the provided callback and options.
     * @private
     */
    async processMessages(messages, callback, options) {
        let abort = false;
        const messagesOrUndef = await Promise.all(messages);
        let processedMessages = messagesOrUndef.filter(isDefined);
        if (this.shouldReverseOrder(options)) {
            processedMessages = processedMessages.reverse();
        }
        await Promise.all(processedMessages.map(async (msg) => {
            if (msg && !abort) {
                abort = Boolean(await callback(msg));
            }
        }));
        return abort;
    }
    /**
     * Determines whether to reverse the order of messages based on the provided options.
     *
     * Messages in pages are ordered from oldest (first) to most recent (last).
     * https://github.com/vacp2p/rfc/issues/533
     *
     * @private
     */
    shouldReverseOrder(options) {
        return (typeof options?.pageDirection === "undefined" ||
            options?.pageDirection === PageDirection.BACKWARD);
    }
    /**
     * @deprecated Use `queryWithOrderedCallback` instead
     **/
    queryOrderedCallback = this.queryWithOrderedCallback;
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     *
     * The callback function takes a `WakuMessage` in input,
     * messages are processed in order:
     * - oldest to latest if `options.pageDirection` == { @link PageDirection.FORWARD }
     * - latest to oldest if `options.pageDirection` == { @link PageDirection.BACKWARD }
     *
     * The ordering may affect performance.
     * The ordering depends on the behavior of the remote store node.
     * If strong ordering is needed, you may need to handle this at application level
     * and set your own timestamps too (the WakuMessage timestamps are not certified).
     *
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     */
    async queryWithOrderedCallback(decoders, callback, options) {
        for await (const promises of this.queryGenerator(decoders, options)) {
            if (await this.processMessages(promises, callback, options))
                break;
        }
    }
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     * The callback function takes a `Promise<WakuMessage>` in input,
     * useful if messages need to be decrypted and performance matters.
     *
     * The order of the messages passed to the callback is as follows:
     * - within a page, messages are expected to be ordered from oldest to most recent
     * - pages direction depends on { @link QueryOptions.pageDirection }
     *
     * Do note that the resolution of the `Promise<WakuMessage | undefined` may
     * break the order as it may rely on the browser decryption API, which in turn,
     * may have a different speed depending on the type of decryption.
     *
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     */
    async queryWithPromiseCallback(decoders, callback, options) {
        let abort = false;
        for await (const page of this.queryGenerator(decoders, options)) {
            const _promises = page.map(async (msgPromise) => {
                if (abort)
                    return;
                abort = Boolean(await callback(msgPromise));
            });
            await Promise.all(_promises);
            if (abort)
                break;
        }
    }
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     *
     * This is a generator, useful if you want most control on how messages
     * are processed.
     *
     * The order of the messages returned by the remote Waku node SHOULD BE
     * as follows:
     * - within a page, messages SHOULD be ordered from oldest to most recent
     * - pages direction depends on { @link QueryOptions.pageDirection }
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     *
     * This API only supports querying a single pubsub topic at a time.
     * If multiple decoders are provided, they must all have the same pubsub topic.
     * @throws If multiple decoders with different pubsub topics are provided.
     * @throws If no decoders are provided.
     * @throws If no decoders are found for the provided pubsub topic.
     */
    async *queryGenerator(decoders, options) {
        if (decoders.length === 0) {
            throw new Error("No decoders provided");
        }
        let startTime, endTime;
        if (options?.timeFilter) {
            startTime = options.timeFilter.startTime;
            endTime = options.timeFilter.endTime;
        }
        // convert array to set to remove duplicates
        const uniquePubSubTopicsInQuery = Array.from(new Set(decoders.map((decoder) => decoder.pubsubTopic)));
        // If multiple pubsub topics are provided, throw an error
        if (uniquePubSubTopicsInQuery.length > 1) {
            throw new Error("API does not support querying multiple pubsub topics at once");
        }
        // we can be certain that there is only one pubsub topic in the query
        const pubSubTopicForQuery = uniquePubSubTopicsInQuery[0];
        ensurePubsubTopicIsConfigured(pubSubTopicForQuery, this.pubsubTopics);
        // check that the pubsubTopic from the Cursor and Decoder match
        if (options?.cursor?.pubsubTopic &&
            options.cursor.pubsubTopic !== pubSubTopicForQuery) {
            throw new Error(`Cursor pubsub topic (${options?.cursor?.pubsubTopic}) does not match decoder pubsub topic (${pubSubTopicForQuery})`);
        }
        const decodersAsMap = new Map();
        decoders.forEach((dec) => {
            if (decodersAsMap.has(dec.contentTopic)) {
                throw new Error("API does not support different decoder per content topic");
            }
            decodersAsMap.set(dec.contentTopic, dec);
        });
        const contentTopics = decoders
            .filter((decoder) => decoder.pubsubTopic === pubSubTopicForQuery)
            .map((dec) => dec.contentTopic);
        if (contentTopics.length === 0) {
            throw new Error("No decoders found for topic " + pubSubTopicForQuery);
        }
        const queryOpts = Object.assign({
            pubsubTopic: pubSubTopicForQuery,
            pageDirection: PageDirection.BACKWARD,
            pageSize: DefaultPageSize
        }, options, { contentTopics, startTime, endTime });
        const peer = (await this.getPeers({
            numPeers: this.NUM_PEERS_PROTOCOL,
            maxBootstrapPeers: 1
        }))[0];
        for await (const messages of paginate(this.getStream.bind(this, peer), queryOpts, decodersAsMap, options?.cursor)) {
            yield messages;
        }
    }
}
async function* paginate(streamFactory, queryOpts, decoders, cursor) {
    if (queryOpts.contentTopics.toString() !==
        Array.from(decoders.keys()).toString()) {
        throw new Error("Internal error, the decoders should match the query's content topics");
    }
    let currentCursor = cursor;
    while (true) {
        queryOpts.cursor = currentCursor;
        const historyRpcQuery = HistoryRpc.createQuery(queryOpts);
        log.info("Querying store peer", `for (${queryOpts.pubsubTopic})`, queryOpts.contentTopics);
        const stream = await streamFactory();
        const res = await pipe([historyRpcQuery.encode()], lp.encode, stream, lp.decode, async (source) => await all(source));
        const bytes = new Uint8ArrayList();
        res.forEach((chunk) => {
            bytes.append(chunk);
        });
        const reply = historyRpcQuery.decode(bytes);
        if (!reply.response) {
            log.warn("Stopping pagination due to store `response` field missing");
            break;
        }
        const response = reply.response;
        if (response.error && response.error !== HistoryError.NONE) {
            throw "History response contains an Error: " + response.error;
        }
        if (!response.messages || !response.messages.length) {
            log.warn("Stopping pagination due to store `response.messages` field missing or empty");
            break;
        }
        log.error(`${response.messages.length} messages retrieved from store`);
        yield response.messages.map((protoMsg) => {
            const contentTopic = protoMsg.contentTopic;
            if (typeof contentTopic !== "undefined") {
                const decoder = decoders.get(contentTopic);
                if (decoder) {
                    return decoder.fromProtoObj(queryOpts.pubsubTopic, toProtoMessage(protoMsg));
                }
            }
            return Promise.resolve(undefined);
        });
        const nextCursor = response.pagingInfo?.cursor;
        if (typeof nextCursor === "undefined") {
            // If the server does not return cursor then there is an issue,
            // Need to abort, or we end up in an infinite loop
            log.warn("Stopping pagination due to `response.pagingInfo.cursor` missing from store response");
            break;
        }
        currentCursor = nextCursor;
        const responsePageSize = response.pagingInfo?.pageSize;
        const queryPageSize = historyRpcQuery.query?.pagingInfo?.pageSize;
        if (
        // Response page size smaller than query, meaning this is the last page
        responsePageSize &&
            queryPageSize &&
            responsePageSize < queryPageSize) {
            break;
        }
    }
}
export async function createCursor(message) {
    if (!message ||
        !message.timestamp ||
        !message.payload ||
        !message.contentTopic) {
        throw new Error("Message is missing required fields");
    }
    const contentTopicBytes = utf8ToBytes(message.contentTopic);
    const digest = sha256(concat([contentTopicBytes, message.payload]));
    const messageTime = BigInt(message.timestamp.getTime()) * BigInt(1000000);
    return {
        digest,
        pubsubTopic: message.pubsubTopic,
        senderTime: messageTime,
        receiverTime: messageTime
    };
}
export function wakuStore(init = {}) {
    return (libp2p) => new Store(libp2p, init);
}
//# sourceMappingURL=index.js.map